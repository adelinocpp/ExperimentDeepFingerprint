#!/usr/bin/env python3
"""
Debug: Verificar pesos do STN (Spatial Transformer Network)
"""

import torch
import numpy as np
from pathlib import Path

from models_base import DeepPrintBaseline

print("="*60)
print("DEBUG: ANALISANDO PESOS DO STN")
print("="*60)

# Carregar modelo
print("\n1. Carregando modelo...")
model = DeepPrintBaseline(num_classes=6000, texture_embedding_dims=96, minutia_embedding_dims=96)
checkpoint_path = Path("exp0_baseline/checkpoints/checkpoint_latest.pt")
checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
model.load_state_dict(checkpoint["model_state_dict"], strict=False)

epoch = checkpoint.get('epoch', '?')
print(f"   Modelo carregado (√©poca {epoch})")

# Analisar pesos do STN
print("\n" + "="*60)
print("AN√ÅLISE DOS PESOS DO STN")
print("="*60)

stn = model.localization

print("\nüìä √öLTIMA CAMADA DO STN (fc_loc[2] - gera theta):")
fc_final = stn.fc_loc[2]  # Linear(64, 3)

weight = fc_final.weight.data.numpy()
bias = fc_final.bias.data.numpy()

print(f"   Weight shape: {weight.shape}")
print(f"   Bias shape: {bias.shape}")

print(f"\n   Weight stats:")
print(f"   Min:  {weight.min():.6f}")
print(f"   Max:  {weight.max():.6f}")
print(f"   Mean: {weight.mean():.6f}")
print(f"   Std:  {weight.std():.6f}")
print(f"   Norm: {np.linalg.norm(weight):.6f}")

print(f"\n   Bias: {bias}")

# Verificar se pesos s√£o ~zero (n√£o foram treinados)
weight_is_zero = np.abs(weight).max() < 1e-6
bias_is_zero = np.abs(bias).max() < 1e-6

if weight_is_zero and bias_is_zero:
    print("\n   ‚ùå PROBLEMA CR√çTICO: Pesos da √∫ltima camada STN s√£o ZERO!")
    print("   ‚Üí STN n√£o foi treinado!")
    print("   ‚Üí Sempre retorna [0, 0, 0] = transforma√ß√£o identidade")
elif weight_is_zero:
    print("\n   ‚ùå PROBLEMA: Weight √© zero mas bias n√£o")
    print("   ‚Üí STN sempre retorna bias = transforma√ß√£o constante")
else:
    print("\n   ‚úì Pesos foram treinados (n√£o s√£o zero)")
    print("   ‚Üí STN deveria funcionar corretamente")

# Testar output do STN com inputs sint√©ticos
print("\n" + "="*60)
print("TESTE: Output do STN com inputs diferentes")
print("="*60)

stn.eval()

# Criar 3 imagens diferentes (ru√≠do aleat√≥rio)
torch.manual_seed(42)
img1 = torch.randn(1, 1, 299, 299)
torch.manual_seed(123)
img2 = torch.randn(1, 1, 299, 299) 
torch.manual_seed(456)
img3 = torch.randn(1, 1, 299, 299)

print("\n   Passando 3 imagens DIFERENTES pelo STN...")
with torch.no_grad():
    out1 = stn(img1)
    out2 = stn(img2)
    out3 = stn(img3)

# Verificar se outputs s√£o diferentes
diff_12 = torch.abs(out1 - out2).mean().item()
diff_13 = torch.abs(out1 - out3).mean().item()
diff_23 = torch.abs(out2 - out3).mean().item()

print(f"\n   Diferen√ßa out1 vs out2: {diff_12:.6f}")
print(f"   Diferen√ßa out1 vs out3: {diff_13:.6f}")
print(f"   Diferen√ßa out2 vs out3: {diff_23:.6f}")

if diff_12 < 1e-6 and diff_13 < 1e-6:
    print("\n   ‚ùå CONFIRMADO: STN retorna MESMA transforma√ß√£o para inputs diferentes!")
else:
    print("\n   ‚úì STN retorna transforma√ß√µes diferentes")

# Analisar theta gerado
print("\n" + "="*60)
print("AN√ÅLISE DO THETA GERADO")
print("="*60)

with torch.no_grad():
    # Passar pela localization network
    resized_x1 = stn.resize(img1)
    xs1 = stn.localization(resized_x1)
    xs1_flat = xs1.view(-1, 8 * 8 * 64)
    theta_xy1 = stn.fc_loc(xs1_flat)
    
    resized_x2 = stn.resize(img2)
    xs2 = stn.localization(resized_x2)
    xs2_flat = xs2.view(-1, 8 * 8 * 64)
    theta_xy2 = stn.fc_loc(xs2_flat)

print(f"\n   Theta para img1: {theta_xy1[0].numpy()}")
print(f"   Theta para img2: {theta_xy2[0].numpy()}")

theta_diff = torch.abs(theta_xy1 - theta_xy2).mean().item()
print(f"\n   Diferen√ßa entre thetas: {theta_diff:.6f}")

if theta_diff < 1e-6:
    print(f"\n   ‚ùå PROBLEMA: fc_loc retorna MESMO theta para inputs diferentes!")
    print(f"   ‚Üí Pesos provavelmente n√£o foram treinados")
else:
    print(f"\n   ‚úì fc_loc gera thetas diferentes")

# Verificar features antes do fc_loc
print("\nüìä Features ANTES do fc_loc:")
print(f"   xs1_flat: min={xs1_flat.min():.6f}, max={xs1_flat.max():.6f}, mean={xs1_flat.mean():.6f}")
print(f"   xs2_flat: min={xs2_flat.min():.6f}, max={xs2_flat.max():.6f}, mean={xs2_flat.mean():.6f}")

feat_diff = torch.abs(xs1_flat - xs2_flat).mean().item()
print(f"\n   Diferen√ßa entre features: {feat_diff:.6f}")

if feat_diff < 1e-6:
    print(f"\n   ‚ùå PROBLEMA: Convolu√ß√µes do STN retornam MESMAS features!")
else:
    print(f"\n   ‚úì Convolu√ß√µes do STN funcionam corretamente")

print("\n" + "="*60)
print("CONCLUS√ÉO")
print("="*60)

if weight_is_zero and bias_is_zero:
    print("\nüö® CAUSA RAIZ: √öltima camada do STN n√£o foi treinada (pesos=0)")
    print("\nSOLU√á√ïES:")
    print("1. Verificar se STN est√° no optimizer (par√¢metros inclu√≠dos?)")
    print("2. Verificar se gradientes chegam ao STN (backward pass)")
    print("3. Considerar remover STN temporariamente para testar")
elif diff_12 < 1e-6:
    print("\nüö® PROBLEMA: STN gera mesma transforma√ß√£o apesar de pesos != 0")
    print("   ‚Üí Bug no forward ou problema com BatchNorm em eval()")
else:
    print("\n‚úì STN parece OK com inputs sint√©ticos")
    print("   ‚Üí Problema pode ser espec√≠fico com imagens reais do dataset")

print("="*60)
