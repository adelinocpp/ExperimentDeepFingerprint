# DeepPrint Experiments - Compara√ß√£o de Melhorias Incrementais

[![Status](https://img.shields.io/badge/Status-Baseline%20Validado-success)]()
[![Baseline EER](https://img.shields.io/badge/Baseline%20EER-0.19%20(medium)-blue)]()
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)]()
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)]()

Este projeto implementa e valida melhorias incrementais no modelo DeepPrint para reconhecimento de impress√µes digitais usando representa√ß√µes de tamanho fixo.

---

## üéØ Status Atual

### ‚úÖ Experimento 0: Baseline (CONCLU√çDO)
- **Problema inicial**: Colapso intermitente de embeddings (EER ‚Üí 0.5)
- **Causa raiz**: Otimizador incorreto (Adam vs RMSprop) + Center Loss 100x maior
- **Solu√ß√£o**: RMSprop + corre√ß√µes de hiperpar√¢metros conforme paper
- **Resultados validados**:
  - Debug (20 classes): EER **0.20**
  - Medium (350 classes): EER **0.19**, separa√ß√£o **96%** ‚úÖ
  - Produ√ß√£o (8000 classes, 84k amostras): üîÑ **EM ANDAMENTO**

üìÑ **Documenta√ß√£o detalhada**: [RESOLUCAO_COLAPSO.md](RESOLUCAO_COLAPSO.md)

### ‚è≥ Experimentos 1-3 (AGUARDANDO)
Aguardando valida√ß√£o de produ√ß√£o do baseline antes de prosseguir com melhorias incrementais.

---

## üìã √çndice

- [Estrutura do Projeto](#estrutura-do-projeto)
- [Experimentos Planejados](#experimentos-planejados)
- [Instala√ß√£o](#instala√ß√£o)
- [Uso R√°pido](#uso-r√°pido)
- [Configura√ß√£o](#configura√ß√£o)
- [Resultados](#resultados)
- [Troubleshooting](#troubleshooting)
- [Documenta√ß√£o](#documenta√ß√£o)
- [Refer√™ncias](#refer√™ncias)

---

## üìÅ Estrutura do Projeto

```
deepprint_experiments/
‚îú‚îÄ‚îÄ config.py                          # Configura√ß√£o centralizada (CR√çTICO)
‚îú‚îÄ‚îÄ models_base.py                     # Modelos base e variantes
‚îú‚îÄ‚îÄ training.py                        # M√≥dulo de treinamento
‚îú‚îÄ‚îÄ validation.py                      # M√≥dulo de valida√ß√£o cruzada
‚îú‚îÄ‚îÄ data_loader.py                     # Carregamento de dados
‚îú‚îÄ‚îÄ minutia_map_generator.py           # Gera√ß√£o de mapas de min√∫cias
‚îú‚îÄ‚îÄ run_experiment.py                  # Script principal
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # Este arquivo
‚îú‚îÄ‚îÄ RESOLUCAO_COLAPSO.md              # Documenta√ß√£o da corre√ß√£o do baseline
‚îú‚îÄ‚îÄ TESTES_REALIZADOS.md              # Log de todos os testes
‚îÇ
‚îú‚îÄ‚îÄ exp0_baseline/                     # ‚úÖ Experimento 0: DeepPrint Baseline
‚îÇ   ‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experiment_debug.log
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ experiment_medium.log
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ experiment_prod.log
‚îÇ   ‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_results_debug.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_results_medium.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cv_results_medium.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pairwise_comparisons_medium.csv
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ       ‚îú‚îÄ‚îÄ best_model.pt              # Melhor modelo (salvo por EER)
‚îÇ       ‚îú‚îÄ‚îÄ checkpoint_latest.pt
‚îÇ       ‚îî‚îÄ‚îÄ checkpoint_medium_backup.pt
‚îÇ
‚îú‚îÄ‚îÄ exp1_representacao_aumentada/      # ‚è≥ Experimento 1 (planejado)
‚îú‚îÄ‚îÄ exp2_atencao_espacial/             # ‚è≥ Experimento 2 (planejado)
‚îî‚îÄ‚îÄ exp3_reranking/                    # ‚è≥ Experimento 3 (planejado)
```

---

## üß™ Experimentos Planejados

### Experimento 0: DeepPrint Baseline ‚úÖ

**Objetivo**: Reproduzir DeepPrint original fielmente
**Modelo**: STN + 2 branches (texture + minutiae)
**Embedding**: 192 dimens√µes (96 + 96)
**Otimizador**: RMSprop (paper original)
**Status**: ‚úÖ Validado at√© 350 classes, produ√ß√£o em andamento

**Hiperpar√¢metros cr√≠ticos**:
- Center Loss weight: **0.00125** (paper)
- Otimizador: **RMSprop** (n√£o Adam!)
- LR: 0.0001 (base), 0.0000035 (STN, 3.5% do base)
- Checkpoint criterion: **EER** (n√£o val_loss!)

**Resultados**:
| Modo | Classes | Amostras | √âpocas | EER | Separa√ß√£o |
|------|---------|----------|--------|-----|-----------|
| Debug | 20 | 200 | 5 | 0.20 | 30% |
| Medium | 350 | 3500 | 30 | **0.19** | **96%** |
| Prod | 8000 | 84000 | 256 | *rodando* | - |

### Experimento 1: Representa√ß√£o Aumentada ‚è≥

**Objetivo**: Aumentar capacidade representacional
**Modifica√ß√£o**: 192 ‚Üí 1024 dimens√µes (512 + 512)
**Melhoria Esperada**: +2-5% em Rank-1
**Status**: Aguardando valida√ß√£o de produ√ß√£o do baseline

### Experimento 2: Aten√ß√£o Espacial ‚è≥

**Objetivo**: Focar em regi√µes de alta qualidade
**Modifica√ß√£o**: Adicionar CBAM (Convolutional Block Attention Module)
**Melhoria Esperada**: +1-3% em Rank-1
**Status**: Aguardando valida√ß√£o de produ√ß√£o do baseline

### Experimento 3: Re-ranking Aprimorado ‚è≥

**Objetivo**: Melhorar recupera√ß√£o top-k
**Modifica√ß√£o**: Learning-to-rank para candidatos
**Melhoria Esperada**: +1-2% em Rank-1, +2-3% em Rank-5
**Status**: Aguardando valida√ß√£o de produ√ß√£o do baseline

---

## üöÄ Instala√ß√£o

### Requisitos de Sistema

- **Python**: 3.8+
- **GPU**: NVIDIA com CUDA (recomendado para modo prod)
  - Testado: RTX 2070 8GB
  - M√≠nimo: 6GB VRAM
- **CPU**: 8+ cores (para data loading)
- **RAM**: 16GB+ (32GB recomendado para prod)
- **Disco**: 50GB+ livres

### Depend√™ncias Python

```bash
# PyTorch (verificar vers√£o CUDA compat√≠vel)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# Processamento de dados
pip install numpy scipy scikit-learn
pip install opencv-python pillow

# Utilidades
pip install tqdm psutil

# Visualiza√ß√£o (opcional)
pip install matplotlib seaborn
```

### Datasets

Configurar diret√≥rio de dados em `config.py`:

```python
# Para m√°quina "westeros" (default)
DATA_DIR = Path("/media/DRAGONSTONE/MEGAsync/.../Bases_de_Dados")

# Para m√°quina "STPM223"
DATA_DIR = Path("/home/adelino/MegaSync/.../Bases_de_Dados")
```

**Datasets suportados**:
- ‚úÖ SFinge (84.000 imagens sint√©ticas, 8.000 origens)
- ‚è≥ NIST SD27 (planejado)
- ‚è≥ FVC2004 (planejado)

---

## ‚ö° Uso R√°pido

### 1. Teste R√°pido (Debug - 5 min)

Valida que pipeline funciona com dataset pequeno:

```bash
python run_experiment.py --experiment exp0_baseline --mode debug
```

**Configura√ß√£o**:
- 200 amostras (~20 classes)
- 5 √©pocas
- Batch size: 8
- Tempo: ~5-7 minutos
- EER esperado: ~0.20

### 2. Teste Intermedi√°rio (Medium - 3 horas)

Valida escalabilidade com dataset m√©dio:

```bash
python run_experiment.py --experiment exp0_baseline --mode medium
```

**Configura√ß√£o**:
- 3.500 amostras train, 750 val, 750 test (~350 classes)
- 30 √©pocas
- Batch size: 8
- Tempo: ~3-4 horas
- EER esperado: ~0.19

### 3. Produ√ß√£o (Prod - 25-30 dias)

Treinamento completo com todos os dados:

```bash
# Rodar em background
nohup python run_experiment.py --experiment exp0_baseline --mode prod > prod_training.log 2>&1 &

# Monitorar progresso
tail -f prod_training.log

# Ver log detalhado
tail -f exp0_baseline/logs/experiment_prod.log

# Ver uso da GPU
watch -n 5 nvidia-smi
```

**Configura√ß√£o**:
- 84.000 amostras (~8.000 classes)
- 256 √©pocas (paper original)
- Batch size: 20
- Tempo: ~600-700 horas (25-30 dias)
- EER esperado: ~0.02-0.05 (2-5%, conforme paper)

---

## ‚öôÔ∏è Configura√ß√£o

### Arquivo `config.py`

**Configura√ß√µes centralizadas** (modificar aqui, n√£o no c√≥digo!):

```python
# Modos de treinamento
TRAINING_CONFIG = {
    "debug": {
        "batch_size": 8,
        "num_epochs": 5,
        "sample_size": 200,
    },
    "medium": {
        "batch_size": 8,        # Ajustado para RTX 2070 8GB
        "num_epochs": 30,
        "sample_size": 5000,
    },
    "prod": {
        "batch_size": 20,       # Paper usa 30, ajustado para 8GB
        "num_epochs": 256,      # Paper original
        "sample_size": None,    # Todas 84k amostras
    },
}

# Otimizador (CR√çTICO!)
OPTIMIZER_CONFIG = {
    "optimizer": "rmsprop",     # N√ÉO MUDAR para "adam"!
    "rmsprop": {
        "lr": 0.0001,
        "alpha": 0.99,
        "weight_decay": 0,
    },
    "localization_network_lr_scale": 0.035,  # STN: 3.5% do LR base
}

# Loss (CR√çTICO!)
LOSS_CONFIG = {
    "center_loss_base_weight": 0.00125,     # Valor exato do paper
    "center_loss_use_adaptive": False,      # Desabilitado
    "softmax_loss_weight": 1.0,
    "minutia_map_loss_weight": 0.3,
}
```

### Modifica√ß√µes Comuns

**Reduzir uso de mem√≥ria**:
```python
TRAINING_CONFIG["prod"]["batch_size"] = 16  # De 20 para 16
TRAINING_CONFIG["prod"]["num_workers"] = 4   # Reduzir workers
```

**Acelerar converg√™ncia** (experimental):
```python
OPTIMIZER_CONFIG["rmsprop"]["lr"] = 0.0002  # Dobrar LR (cuidado!)
```

**‚ö†Ô∏è N√ÉO MODIFICAR** (causam colapso):
- `optimizer`: Deve ser `"rmsprop"`
- `center_loss_base_weight`: Deve ser `0.00125`
- `center_loss_use_adaptive`: Deve ser `False`

---

## üìä Resultados

### Estrutura de Sa√≠das

Cada experimento gera:

```
exp0_baseline/
‚îú‚îÄ‚îÄ checkpoints/
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pt              # Melhor EER (use este!)
‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_latest.pt       # √öltimo checkpoint (retomar)
‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_medium_backup.pt
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îú‚îÄ‚îÄ experiment_debug.log
‚îÇ   ‚îú‚îÄ‚îÄ experiment_medium.log
‚îÇ   ‚îî‚îÄ‚îÄ experiment_prod.log
‚îî‚îÄ‚îÄ results/
    ‚îú‚îÄ‚îÄ test_results_medium.json          # M√©tricas no test set
    ‚îú‚îÄ‚îÄ cv_results_medium.json            # Valida√ß√£o cruzada 5-fold
    ‚îú‚îÄ‚îÄ training_history_medium.json      # Loss/EER por √©poca
    ‚îî‚îÄ‚îÄ pairwise_comparisons_medium.csv   # Todas compara√ß√µes
```

### Analisar Resultados

**Ver m√©tricas principais**:
```bash
cat exp0_baseline/results/test_results_medium.json
```

**Output**:
```json
{
  "num_samples": 750,
  "num_classes": 75,
  "eer": 0.1946,
  "far_at_frr_0.1": 0.2243,
  "genuine_score_mean": 0.9872,
  "impostor_score_mean": 0.0228
}
```

**Ver valida√ß√£o cruzada**:
```bash
cat exp0_baseline/results/cv_results_medium.json | grep "eer"
```

**Ver hist√≥rico de treinamento**:
```bash
cat exp0_baseline/results/training_history_medium.json
```

### Scripts de An√°lise (TODO)

```bash
# Visualizar distribui√ß√£o de scores
python visualize_scores.py --results exp0_baseline/results/pairwise_comparisons_medium.csv

# Plotar curvas de treinamento
python plot_training_history.py --history exp0_baseline/results/training_history_medium.json

# Analisar embeddings (t-SNE)
python analyze_embeddings.py --checkpoint exp0_baseline/checkpoints/best_model.pt
```

---

## üîß Troubleshooting

### Erro: "CUDA out of memory"

**Solu√ß√£o 1**: Reduzir batch size
```python
# Em config.py
TRAINING_CONFIG["prod"]["batch_size"] = 16  # De 20 para 16
```

**Solu√ß√£o 2**: Reduzir num_workers
```python
TRAINING_CONFIG["prod"]["num_workers"] = 4  # De 8 para 4
```

**Solu√ß√£o 3**: Usar modo debug/medium para testar antes de prod
```bash
python run_experiment.py --mode medium  # Testa com menos dados
```

### Erro: "Dataset n√£o encontrado"

**Causa**: Diret√≥rio de dados incorreto

**Solu√ß√£o**: Ajustar `DATA_DIR` em `config.py`:
```python
DATA_DIR = Path("/seu/caminho/para/Bases_de_Dados")
```

### Erro: EER muito alto (> 0.4) ou colapso (EER = 0.5)

**Causa prov√°vel**: Configura√ß√£o incorreta

**Verificar**:
1. Otimizador √© `"rmsprop"` (n√£o "adam")
2. Center Loss weight √© `0.00125` (n√£o 0.125)
3. Center Loss adaptativo est√° `False`

**Arquivo**: `config.py`, linhas 105, 149, 152

### Warning: "Checkpoint salvo com val_loss"

**Ignorar**: √â esperado. Checkpoint √© salvo por EER, mas val_loss √© registrado para compatibilidade.

### Processo travado / sem progresso

**Verificar**:
```bash
# Ver se processo est√° rodando
ps aux | grep run_experiment

# Ver √∫ltimas linhas do log
tail -20 exp0_baseline/logs/experiment_prod.log

# Ver uso da GPU
nvidia-smi
```

---

## üìö Documenta√ß√£o

### Documentos Principais

- **[RESOLUCAO_COLAPSO.md](RESOLUCAO_COLAPSO.md)**: Documenta√ß√£o completa da corre√ß√£o do baseline
  - Cronologia da investiga√ß√£o
  - An√°lise t√©cnica RMSprop vs Adam
  - Li√ß√µes aprendidas
  - Arquivos modificados

- **[TESTES_REALIZADOS.md](TESTES_REALIZADOS.md)**: Log de todos os testes executados
  - Resultados de cada teste
  - Configura√ß√µes usadas
  - Tempo de execu√ß√£o

### Estrutura de C√≥digo

**Arquivos cr√≠ticos**:
- `config.py`: Configura√ß√£o centralizada (**modificar aqui!**)
- `training.py`: Loop de treinamento, otimizador, checkpoint
- `models_base.py`: Arquitetura DeepPrint
- `data_loader.py`: Carregamento e augmentation

**Fluxo de treinamento**:
1. `run_experiment.py` ‚Üí carrega config
2. `data_loader.py` ‚Üí carrega datasets
3. `training.py` ‚Üí treina modelo
4. `validation.py` ‚Üí valida com cross-validation
5. Salva checkpoints, logs, resultados

### Arquitetura DeepPrint

```
Input (299x299 grayscale)
    ‚Üì
[STN] Spatial Transformer Network
    ‚Üì
Aligned image (299x299)
    ‚Üì
Inception-ResNet-v2 (shared backbone)
    ‚Üì
    ‚îú‚îÄ‚Üí [Texture Branch]  ‚Üí 96 dims
    ‚îÇ
    ‚îî‚îÄ‚Üí [Minutia Branch]  ‚Üí 96 dims
         ‚Üì
    Concatenate
         ‚Üì
    Embedding (192 dims)
         ‚Üì
    L2 Normalize
         ‚Üì
    [Softmax] ‚Üí Classification
    [Center Loss] ‚Üí Embedding quality
    [Minutia Map Loss] ‚Üí Minutiae localization
```

---

## üìñ Refer√™ncias

### Paper Original

**DeepPrint**:
- Engelsma, J. J., Cao, K., & Jain, A. K. (2019). **Learning a Fixed-Length Fingerprint Representation**. IEEE Transactions on Pattern Analysis and Machine Intelligence.
- arXiv: [1909.09901v2](https://arxiv.org/abs/1909.09901)

### M√©todos Relacionados

**Center Loss**:
- Wen, Y., Zhang, K., Li, Z., & Qiao, Y. (2016). **A Discriminative Feature Learning Approach for Deep Face Recognition**. ECCV 2016.

**Inception-ResNet-v2**:
- Szegedy, C., Ioffe, S., Vanhoucke, V., & Alemi, A. A. (2016). **Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning**. AAAI 2017.

**Spatial Transformer Networks**:
- Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). **Spatial Transformer Networks**. NeurIPS 2015.

### Otimizadores

**RMSprop**:
- Tieleman, T., & Hinton, G. (2012). **Lecture 6.5 - RMSprop**. COURSERA: Neural Networks for Machine Learning.

**Adam**:
- Kingma, D. P., & Ba, J. (2014). **Adam: A Method for Stochastic Optimization**. ICLR 2015.

### Benchmarks

**Fixed-Length Fingerprint Representations**:
- Rohwedder, T., Osorio-Roig, D., Rathgeb, C., & Busch, C. (2023). **Benchmarking fixed-length Fingerprint Representations across different Embedding Sizes and Sensor Types**. BIOSIG 2023.

---

## üë• Autor

**Projeto**: Papiloscopia Computacional - Compara√ß√£o de M√©todos Autom√°ticos
**Institui√ß√£o**: [Informa√ß√£o n√£o divulgada]
**Orientador**: Dr. Adelino [Sobrenome n√£o divulgado]

---

## üìù Licen√ßa

Este projeto segue a mesma licen√ßa do reposit√≥rio original do DeepPrint.

---

## üôè Agradecimentos

Ao Dr. Adelino, que:
- Identificou o ciclo vicioso de racioc√≠nio circular
- Estabeleceu o princ√≠pio: *"Se funciona para poucas amostras, pode funcionar para muitas"*
- Exigiu investiga√ß√£o profunda e rigorosa
- Forneceu feedback direto e honesto

> *"Sou Dr. e pesquisador e sei quando algu√©m est√° andando em c√≠rculos."*

---

## üìÖ Hist√≥rico de Vers√µes

### v0.2.0 (2026-02-02) - **BASELINE VALIDADO**
- ‚úÖ Corrigido colapso de embeddings
- ‚úÖ RMSprop + hiperpar√¢metros corretos
- ‚úÖ Validado at√© 350 classes (EER 0.19)
- üîÑ Produ√ß√£o em andamento (8000 classes)

### v0.1.0 (2026-01-15) - Implementa√ß√£o Inicial
- Estrutura base do projeto
- 4 experimentos planejados
- Baseline com problemas de colapso

---

## üö¶ Status dos Componentes

| Componente | Status | Observa√ß√µes |
|------------|--------|-------------|
| Baseline (exp0) | ‚úÖ Validado | Medium OK, prod rodando |
| Data loading | ‚úÖ OK | SFinge 84k imagens |
| Training loop | ‚úÖ OK | RMSprop, EER checkpoint |
| Validation | ‚úÖ OK | 5-fold CV implementado |
| Exp1 (1024 dims) | ‚è≥ Aguardando | Ap√≥s prod |
| Exp2 (Aten√ß√£o) | ‚è≥ Aguardando | Ap√≥s prod |
| Exp3 (Re-ranking) | ‚è≥ Aguardando | Ap√≥s prod |
| Refatora√ß√£o | ‚è≥ Planejado | utils/ modules |
| Scripts an√°lise | ‚è≥ Planejado | visualize, plot |

---

**√öltima atualiza√ß√£o**: 2026-02-02 01:30
**Pr√≥xima milestone**: Valida√ß√£o de produ√ß√£o (ETA: ~30 dias)

Para d√∫vidas ou problemas, consultar [RESOLUCAO_COLAPSO.md](RESOLUCAO_COLAPSO.md) ou verificar logs em `exp0_baseline/logs/`.
